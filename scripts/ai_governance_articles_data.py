# -*- coding: utf-8 -*-
"""
AIガバナンスブログ 記事別データ（Type C: 実務の問い・定義・失敗3例・チェックリスト・参考・固有の一文）
slug -> dict(question, definition, mapping_note, failures[3], unique_sentence, checklist[], refs[(label, url)])
"""
import re

# 共通の参照（記事で使い回す）
REF_NIST = ("NIST AI RMF・生成AIプロファイル", "https://www.nist.gov/itl/ai-risk-management-framework")
REF_METI = ("AI事業者ガイドライン（経済産業省）", "https://www.meti.go.jp/shingikai/mono_info_service/ai_shakai_jisso/pdf/20250328_2.pdf")
REF_ISO42001 = ("ISO/IEC 42001（AIMS）", "https://www.iso.org/standard/42001")
REF_EU_AI_ACT = ("EU AI Act（欧州デジタル戦略）", "https://digital-strategy.ec.europa.eu/en/faqs/navigating-ai-act")
REF_GPAI = ("GPAI Code of Practice（欧州委員会）", "https://digital-strategy.ec.europa.eu/en/policies/contents-code-gpai")

def _q(s):
    """HTML用にダブルクォートをエスケープ（JSX内では使わず、Python側で文字列化する時用）"""
    return s.replace('"', '&quot;') if '"' in s else s

def _short_label(s, max_len=14):
    """Mermaidノード用に短くする（括弧・句読点を除く）。"""
    s = re.sub(r"[（）「」、。\s]+", " ", s).strip()
    return s[:max_len] + ("…" if len(s) > max_len else "")


def _make_infographics(data):
    """記事データから記事別のインフォグラフィック3種を生成（画一化しない）。"""
    failures = data.get("failures", [])[:3]
    checklist = data.get("checklist", [])[:5]
    t = (data.get("_title") or "").split("：")[0] if data.get("_title") else "本テーマ"
    # Mermaid1: 失敗パターンからフロー（記事ごとに文言が違う）
    f1 = _short_label(failures[0], 12) if len(failures) > 0 else "失敗1"
    f2 = _short_label(failures[1], 12) if len(failures) > 1 else "失敗2"
    f3 = _short_label(failures[2], 12) if len(failures) > 2 else "失敗3"
    mermaid_1 = f"""graph LR
    A[{f1}] --> B[{f2}]
    B --> C[{f3}]
    C --> D[手続きで防止]
    style A fill:#fee2e2,stroke:#b91c1c
    style B fill:#fef9c3,stroke:#ca8a04
    style C fill:#fef9c3,stroke:#ca8a04
    style D fill:#dcfce7,stroke:#15803d"""
    # Mermaid2: チェックリストから3箱（記事ごとに項目が違う）
    c1 = _short_label(checklist[0], 10) if len(checklist) > 0 else "確認1"
    c2 = _short_label(checklist[1], 10) if len(checklist) > 1 else "確認2"
    c3 = _short_label(checklist[2], 10) if len(checklist) > 2 else "確認3"
    mermaid_2 = f"""graph TD
    subgraph 確認
        X[{c1}]
        Y[{c2}]
        Z[{c3}]
    end
    style X fill:#e0f2fe,stroke:#003E68
    style Y fill:#e0f2fe,stroke:#003E68
    style Z fill:#e0f2fe,stroke:#003E68"""
    # カード: 観点・要件（チェックリスト） vs よくある失敗（failures）— 記事ごとに中身が違う
    card_left_items = checklist[:4] if checklist else ["RACIの文書化", "手続きの分離", "記録の設計"]
    card_right_items = failures[:4] if failures else ["責任の曖昧さ", "証跡不足", "モニタリング欠如"]
    return {
        "mermaid_1": mermaid_1,
        "mermaid_2": mermaid_2,
        "card_caption": f"{t}：観点と失敗の対比",
        "card_left_title": "観点・要件（確認したいこと）",
        "card_left_items": card_left_items,
        "card_right_title": "よくある失敗（現場で起きがち）",
        "card_right_items": card_right_items,
    }


def get_article_data(slug, title):
    """slug と title から記事データを返す。CUSTOM にあればそれを使い、なければ title から生成。"""
    t = title.replace(" | RISEby Blog", "").strip()
    custom = CUSTOM.get(slug)
    if custom:
        data = dict(custom)
    else:
        data = {
            "question": f"本稿が解く実務の問いは一つである。{t}を運用に落とすうえで、何を証跡として残し誰が責任を負うかを明確にすることである。",
            "definition": f"<strong>{t.split('：')[0] if '：' in t else t}</strong>を、AIガバナンスの文脈で扱う場合、方針・手続き・記録・継続評価・是正を一体的に設計する必要がある。<strong>監査可能性</strong>は、意思決定・変更・アクセスが記録され説明責任を果たせる状態を指す。",
            "mapping_note": "EU AI Act、NIST AI RMF、各国ガイドライン等を参照し、自社の適用する規制一覧と本テーマの対応関係を一覧表にする。不足があれば手続きを補う。適用可否と最終判断は法務・監査と共同で確認する。",
            "failures": [
                "RACIが曖昧で、申請・承認が滞留するか、監査で「誰が責任か」を指摘される。",
                "記録がログだけでは不十分で、監査で「説明ができない」と指摘される。",
                "継続モニタリングがなく、規制更新や逸脱に後手で気づく。",
            ],
            "unique_sentence": f"多くの組織で、{t.split('：')[0] if '：' in t else '本テーマ'}を「方針だけ」で止めると、監査で証跡不足を指摘されやすい。手続きと記録をそろえておくと説明しやすくなる。",
            "checklist": [
                "RACIを文書化しているか",
                "ポリシーと手続き（申請・審査・承認・記録）を分けているか",
                "記録の保存期間と改ざん耐性を定めているか",
                "継続モニタリング（四半期レビュー等）を組み込んでいるか",
                "インシデント時の報告・是正手続きがあるか",
                "規制・標準との対応表で本テーマをマッピングしたか",
            ],
            "refs": [REF_NIST, REF_METI, REF_ISO42001],
        }
    data["_title"] = t
    data.update(_make_infographics(data))
    del data["_title"]
    return data

# 記事別カスタムデータ（slug -> dict）。未記載の slug は get_article_data のデフォルトで生成。
CUSTOM = {
    "exception-management-control": {
        "question": "本稿が解く実務の問いは一つである。例外をどう扱えば、現場のスピードを落とさずに監査に耐える証跡を残せるか。多くの組織では「例外は都度判断」のままにすると、監査で「誰が何を承認したか説明できない」と指摘されやすい。",
        "definition": "<strong>例外管理</strong>とは、ポリシーで定めた通常ルート以外の利用・導入について、申請・審査・承認・記録をどう扱うかである。監査では例外の数・理由・承認者・証跡が問われる。<strong>AIガバナンス</strong>の文脈では、利用許可の例外（例：機密レベルが高い用途の一時許可）や、評価・手続きの特例を、手続き化し証跡を残すことが求められる。<strong>監査可能性</strong>は、意思決定・変更・アクセスが記録され説明責任を果たせる状態を指す。",
        "mapping_note": "EU AI Act、NIST AI RMF、各国ガイドラインでは「例外管理」が明示されていない場合でも、一般的な統制要求（記録・説明責任・継続評価）に照らすと、例外処理の証跡は監査で求められやすい。自社の適用する規制一覧と「例外管理」の対応関係を一覧表にし、不足があれば手続きを補う。適用可否と最終判断は法務・監査と共同で確認する。",
        "failures": [
            "例外の定義が曖昧で、現場が「これも例外か」と判断に迷い、申請が滞留する。",
            "承認者が一人に集中し、不在時に例外申請が止まる。RACIが不明確で、監査から「誰が最終責任か」を指摘される。",
            "例外の記録がログだけでは不十分で、監査で「承認理由の説明ができない」と指摘される。",
        ],
        "unique_sentence": "例外が「都度の特例」のまま増えると、監査で例外の束が証跡として認められにくく、是正要求につながりやすい。例外の定義・承認者・記録をそろえておくと、監査時に「例外も手続きに乗っている」と説明しやすくなる。",
        "checklist": [
            "例外の定義を文書化しているか",
            "申請・審査・承認のRACIを決めているか",
            "例外申請の記録（誰が・何を・なぜ・いつ）を残す手続きがあるか",
            "例外の有効期限と更新手続きを定めているか",
            "四半期ごとに例外の件数・傾向をレビューしているか",
            "例外に起因するインシデント時の報告・是正手続きがあるか",
            "監査・規制要求との対応表で「例外管理」をマッピングしたか",
        ],
        "refs": [REF_NIST, REF_METI, REF_ISO42001],
    },
    "eu-ai-act-high-risk": {
        "question": "本稿が解く実務の問いは一つである。EU AI Actの高リスクAIについて、適合性評価・QMS・技術文書を「運用に落とす」には何が要るか。規制の要求と自社の証跡設計の対応関係を整理し、監査に耐える形にすることが前提である。",
        "definition": "<strong>EU AI Act</strong>の高リスクAIとは、付属書IIIに列挙される用途（雇用・教育・重要インフラ等）に該当するAIシステムを指す。適合性評価・品質マネジメントシステム（QMS）・技術文書の整備が要求される。<strong>監査可能性</strong>は、これらの要求に照らして「何を記録し、誰が説明するか」を明確にした状態を指す。準拠の可否は審査機関・法務と確認が必要である。",
        "mapping_note": "EU AI Actの高リスク要件（適合性評価・QMS・技術文書）と、自社の統制・手続き・記録の対応関係を一覧表にし、不足箇所を補う。域外適用（ブリュッセル効果）の有無は法務と確認する。準拠の断定はせず、対応関係の整理と説明可能性の向上として位置づける。",
        "failures": [
            "技術文書が「あるが更新されていない」状態で、監査で不整合を指摘される。",
            "QMSと開発・運用の実態が乖離し、監査で「形だけ」と指摘される。",
            "適合性評価の責任者と実務のつながりが曖昧で、説明責任を果たせない。",
        ],
        "unique_sentence": "高リスク用途を「規制後に対応する」と先送りにすると、後から証跡を遡って整えるコストが膨らむ。最初から許可・評価・記録の流れを設計しておくと、監査・当局説明がしやすくなる。",
        "checklist": [
            "自社のAI利用が付属書IIIの高リスクに該当するか確認したか",
            "適合性評価の責任者と手続きを決めているか",
            "QMS文書と開発・運用プロセスを対応づけているか",
            "技術文書の更新頻度と責任者を定めているか",
            "継続的適合性評価（監視・レビュー）を組み込んでいるか",
            "域外適用の有無を法務と確認したか",
        ],
        "refs": [REF_EU_AI_ACT, REF_GPAI, REF_METI],
    },
    "shadow-ai-countermeasures": {
        "question": "本稿が解く実務の問いは一つである。シャドウAI（無許可利用）を減らしつつ、現場の生産性を落とさないには、禁止だけでなく何が必要か。正規ルートの整備と証跡の設計が前提である。",
        "definition": "<strong>シャドウAI</strong>とは、社内ポリシーや承認ルートを経ずに利用されているAI（無料ツールへの機密入力等）を指す。<strong>AIガバナンス</strong>では、禁止だけでなく「許可された環境・手続き」を用意し、記録・監査可能性を確保することが求められる。<strong>監査可能性</strong>は、誰が何を利用したかが記録され説明できる状態である。",
        "mapping_note": "各国ガイドライン・EU AI Act等は、利用の透明性・記録・リスク管理を求める。シャドウAI対策（可視化・正規ルート・記録）とこれらの対応関係を一覧にし、不足を補う。準拠の断定はせず、対応関係の整理とする。",
        "failures": [
            "禁止だけを強化し、正規の利用環境が整っていないため、現場が従わずシャドウが減らない。",
            "可視化ツールを入れても、誰が是正するかが決まっておらず、検知後の対応が止まる。",
            "正規ルートの申請・承認が重く、現場が「面倒」で無許可利用に戻る。",
        ],
        "unique_sentence": "シャドウAIは「取り締まり」だけでは減らず、申請しやすい正規ルートと「記録が残る」メリットを設計すると、現場が正規ルートに寄りやすい。",
        "checklist": [
            "無許可利用の実態（範囲・程度）を把握しているか",
            "正規の利用環境（許可ツール・申請手続き）を整えているか",
            "可視化・検知の責任者と是正手続きを決めているか",
            "申請・承認の負荷が高すぎないか見直しているか",
            "利用ログ・証跡の保存と監査対応を設計しているか",
        ],
        "refs": [REF_NIST, REF_METI, REF_ISO42001],
    },
    "ai-incident-response-escalation": {
        "question": "本稿が解く実務の問いは一つである。AIに関連するインシデントが起きたとき、誰が誰に報告し、当局・顧客にどう説明するか。エスカレーションと説明責任の設計が前提である。",
        "definition": "<strong>AIインシデント</strong>とは、AIシステムの誤動作・バイアス発覚・セキュリティ事象等、説明責任や是正が問われる事象を指す。<strong>エスカレーション</strong>は、一次対応から経営・法務・当局報告までの役割と手順である。<strong>監査可能性</strong>は、発生・対応・報告・是正の記録が残り説明できる状態である。",
        "mapping_note": "EU AI Act等では重大インシデントの当局通知が求められる場合がある。自社の適用規制と「報告・通知」の対応関係を一覧にし、責任者と手順を決める。適用可否は法務・コンプラと確認する。",
        "failures": [
            "エスカレーション先が曖昧で、重大事案が経営・法務に届かず後から発覚する。",
            "当局・顧客向けの説明資料がなく、事後対応が遅れ、信頼を損なう。",
            "インシデントの記録が散在し、監査で「経緯が説明できない」と指摘される。",
        ],
        "unique_sentence": "インシデントは「起きてから動く」のでは遅く、あらかじめ誰が報告し誰が説明するかを決め、テンプレと証跡の型を用意しておくと、実際の発生時に焦らず対応できる。",
        "checklist": [
            "AIインシデントの定義と重大性の基準を決めているか",
            "一次対応・エスカレーション・当局報告のRACIを決めているか",
            "当局・顧客向け説明のテンプレと責任者を用意しているか",
            "発生・対応・是正の記録を残す手続きがあるか",
            "事後レビューと再発防止の手続きがあるか",
        ],
        "refs": [REF_EU_AI_ACT, REF_NIST, REF_METI],
    },
    "evidence-bundle-audit": {
        "question": "本稿が解く実務の問いは一つである。監査法人が欲しい「証跡の束ね方」とは何か。ログ・文書・承認履歴をどうまとめれば、監査に耐えるEvidence Bundleになるか。",
        "definition": "<strong>Evidence Bundle</strong>とは、監査で求められる証跡（意思決定・承認・変更・評価の記録）を、時系列・テーマ別に束ね、説明可能な形で整えた集合である。<strong>監査可能性</strong>は、監査人が「何を・誰が・いつ・なぜ」を追える状態を指す。AIガバナンスでは、利用許可・評価結果・例外・インシデントの記録を束ねることが多い。",
        "mapping_note": "規制・監査基準ごとに「何を証跡とするか」は異なる。自社の適用する監査・規制と、Evidence Bundleの構成の対応関係を一覧にし、不足している証跡を補う。",
        "failures": [
            "証跡が各部門に散在し、監査時に「出せない」「説明できない」となる。",
            "ログだけ渡して「証跡」とすると、監査から「文脈・承認履歴が分からない」と指摘される。",
            "Bundleの更新責任者がおらず、古いまま提出して不整合を指摘される。",
        ],
        "unique_sentence": "監査で「証跡を出せ」と言われてから集め始めると、欠落や不整合が多く、是正要求につながりやすい。日頃からBundleの構成と更新責任者を決めておくと、監査対応が楽になる。",
        "checklist": [
            "監査・規制で求められる証跡のリストを整理しているか",
            "Evidence Bundleの構成（何をどこに束ねるか）を決めているか",
            "Bundleの更新責任者と頻度を決めているか",
            "ログ・文書・承認履歴の対応関係を明示しているか",
            "改ざん耐性・保存期間を満たしているか",
        ],
        "refs": [REF_NIST, REF_ISO42001, REF_METI],
    },
    "continuous-evaluation-drift": {
        "question": "本稿が解く実務の問いは一つである。モデル更新とドリフト（性能・挙動の変化）を、誰がどの頻度で評価し、記録に残すか。継続的評価を運用に落とす設計が前提である。",
        "definition": "<strong>継続的評価</strong>とは、本番中のAIモデルの性能・挙動を定期的に評価し、ドリフトや逸脱を検知・是正する仕組みである。<strong>ドリフト</strong>は、データ分布やモデル出力の変化を指す。<strong>監査可能性</strong>は、評価結果・是正・再評価の記録が残り説明できる状態である。",
        "mapping_note": "EU AI Act（高リスク）やNIST AI RMF等は、継続的なモニタリング・評価を求める。自社の適用規制と「継続的評価」の対応関係を一覧にし、評価頻度・責任者・記録を決める。",
        "failures": [
            "評価の責任者がおらず、モデル更新後に再評価されず本番で不具合が出る。",
            "ドリフト検知はしているが、是正手続きがなく「検知しただけ」で止まる。",
            "評価結果が記録されず、監査で「継続評価をやっている証拠がない」と指摘される。",
        ],
        "unique_sentence": "モデルを「リリースしたら終わり」にすると、ドリフトや規制変更に気づかず、監査・インシデントで初めて問題になる。評価と記録のサイクルを組み込んでおくと、説明責任を果たしやすい。",
        "checklist": [
            "継続評価の責任者と頻度を決めているか",
            "ドリフト検知の方法と閾値を定めているか",
            "是正・再評価の手続きがあるか",
            "評価結果・是正の記録を残しているか",
            "規制・監査要求との対応で「継続評価」をマッピングしたか",
        ],
        "refs": [REF_NIST, REF_EU_AI_ACT, REF_METI],
    },
    "nist-ai-rmf-implementation": {
        "question": "本稿が解く実務の問いは一つである。NIST AI RMFを企業のガバナンスにどう落とし込むか。フレームワークの要求と、自社の体制・手続き・記録の対応関係を整理することが前提である。",
        "definition": "<strong>NIST AI RMF</strong>（AI Risk Management Framework）は、AIのリスクをGovern・Map・Manage・Measureの4関数で扱う枠組みである。規制ではなく指針のため、自社のリスクに合わせて取り入れる。<strong>監査可能性</strong>は、RMFの要求に照らして何を記録し誰が説明するかを明確にした状態を指す。",
        "mapping_note": "NIST AI RMFの4関数と、自社のポリシー・手続き・記録・継続評価の対応関係を一覧にし、不足を補う。準拠の断定はせず、参照して統制を設計する位置づけとする。",
        "failures": [
            "RMFを「読んだだけ」で終え、体制・手続きに落としていない。",
            "MapとManageの責任者が曖昧で、リスク評価と是正が回らない。",
            "Measure（測定・モニタリング）がなく、効果や逸脱を把握できない。",
        ],
        "unique_sentence": "RMFは網羅的であるため、一度に全部やろうとすると形骸化する。自社のリスクが高い領域から、Govern→Map→Manage→Measureの順で区切って取り入れると、運用に乗りやすい。",
        "checklist": [
            "RMFの4関数のうち、自社で優先する領域を決めているか",
            "Govern：方針・役割を文書化しているか",
            "Map：リスクの棚卸しと分類をしているか",
            "Manage：是正・軽減の手続きがあるか",
            "Measure：モニタリング・測定の責任者と記録があるか",
        ],
        "refs": [REF_NIST, REF_METI, REF_ISO42001],
    },
    "iso-42001-aims-introduction": {
        "question": "本稿が解く実務の問いは一つである。ISO/IEC 42001（AIMS）を導入するうえで、何を押さえどこに落とし穴があるか。マネジメントシステム要求を体制・手続き・記録に落とす設計が前提である。",
        "definition": "<strong>ISO/IEC 42001</strong>（AIMS）は、AIマネジメントシステムの国際規格である。方針・リスク評価・運用・監視・改善等の要求があり、認証取得の可否は審査機関の判断による。<strong>監査可能性</strong>は、要求に照らして証跡を残し説明できる状態を指す。準拠・認証の断定はせず、要求を参照した設計とする。",
        "mapping_note": "42001の要求と、自社のポリシー・手続き・記録の対応関係を一覧にし、ギャップを埋める。認証を目指すかは経営判断であり、審査機関との確認が必要である。",
        "failures": [
            "文書だけ整え、実務の運用と乖離し監査で「形だけ」と指摘される。",
            "リスク評価と是正の責任者が曖昧で、PDCAが回らない。",
            "継続的改善の証跡がなく、監査で「やっている証拠がない」と指摘される。",
        ],
        "unique_sentence": "42001は「作って終わり」にすると、更新が止まり規格の趣旨から外れる。四半期ごとの見直しと証跡の更新を組み込んでおくと、認証・監査の負荷が下がる。",
        "checklist": [
            "42001の要求を自社の体制・手続きにマッピングしたか",
            "トップマネジメントのコミットと役割を文書化しているか",
            "リスク評価・是正・監視の責任者と頻度を決めているか",
            "文書の版管理と更新責任者を決めているか",
            "内部監査・マネジメントレビューの証跡を残しているか",
        ],
        "refs": [REF_ISO42001, REF_NIST, REF_METI],
    },
    "japan-ai-guidelines": {
        "question": "本稿が解く実務の問いは一つである。日本のAI事業者ガイドラインを、企業の運用にどう落とすか。ガイドラインの要求と、自社の統制・証跡の対応関係を整理することが前提である。",
        "definition": "<strong>AI事業者ガイドライン</strong>（経済産業省等）は、AIを提供・利用する事業者向けの指針であり、法規制ではない。透明性・説明責任・リスク管理・データ管理等が求められる。<strong>監査可能性</strong>は、これらの考え方に照らして記録・説明ができる状態を指す。",
        "mapping_note": "ガイドラインの項目と、自社のポリシー・手続き・記録の対応関係を一覧にし、不足を補う。Living文書のため、四半期ごとの棚卸しを推奨する。準拠の断定はせず、参照して設計する位置づけとする。",
        "failures": [
            "ガイドラインを「読んだだけ」で、体制・手続きに反映していない。",
            "項目ごとの責任者がおらず、誰が何をやるか曖昧なまま。",
            "ガイドライン改定に気づかず、古い前提で運用している。",
        ],
        "unique_sentence": "ガイドラインはLivingで更新されるため、一度きりの対応では不足する。四半期ごとのホライズンスキャンと自社の対応表の見直しを組み込むと、後手を減らせる。",
        "checklist": [
            "ガイドラインの全項目を自社の統制にマッピングしたか",
            "各項目の責任者（RACI）を決めているか",
            "証跡（記録・承認・評価）を残す手続きがあるか",
            "ガイドラインの更新を追う担当と頻度を決めているか",
        ],
        "refs": [REF_METI, REF_NIST, REF_ISO42001],
    },
}

# 運用5点は全記事共通
OPERATIONAL_FIVE = [
    ("役割と責任（RACI）", "申請・審査・承認・記録・監視・是正の責任者を決め、RACIで明文化する。"),
    ("ポリシー→手続き", "方針を文書化し、申請・審査・承認・例外・更新の手続きを手順化する。自動化と人の判断の切り分けを決める。"),
    ("記録と証跡", "意思決定・変更・アクセスを改ざん耐性のある形で残す。監査で「何を・誰が・いつ」を説明できる設計にする。"),
    ("継続モニタリング", "評価・監視・レビューを定期的に回し、結果を記録する。規制・リスクの変化に気づく仕組みを組み込む。"),
    ("インシデント対応", "報告・是正・再発防止の手続きを決め、記録を残す。当局・顧客への説明責任の担当を決めておく。"),
]
